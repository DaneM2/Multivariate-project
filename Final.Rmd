---
title: "DA410 Final Project"
author: "Dane Turnbull"
date: "3/21/2021"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd(getwd())

```

```{r}
HeartDisease <- read.csv("~/Bellevue College/DA410/HeartDisease.csv")
heart <- HeartDisease
```

```{r Loading in necessary libraries asdf}
library("tidyverse")
library("tidyselect")
library("ggplot2")
library("car")
library("ICSNP")
library("tibble")
library("readr")
library("plotly")
library("DT")
library("mvnormtest")
library("dplyr")
library("caTools")
library("MASS")
library("ROCR")
```

```{r}
#interactive datatable to view data
datatable(heart)
```
```{r}
#box plot to view the 5 continuous variables when target is 0 and 1
f1 <- plot_ly(HeartDisease,
              type = "box") %>% 
  add_boxplot(y = ~trestbps,
              x = ~target,
              name = "trestbps") %>% 
  layout(title = "trestbps",
         xaxis = list(title = "target"),
         yaxis = list(title = "trestbps"))
f1
```

```{r}
f2 <- plot_ly(HeartDisease,
              type = "box") %>% 
  add_boxplot(y = ~chol,
              x = ~target,
              name = "chol") %>% 
  layout(title = "chol",
         xaxis = list(title = "target"),
         yaxis = list(title = "chol"))
f2
```
```{r}
f3 <- plot_ly(HeartDisease,
              type = "box") %>% 
  add_boxplot(y = ~ï..age,
              x = ~target,
              name = "ï..age") %>% 
  layout(title = "ï..age",
         xaxis = list(title = "target"),
         yaxis = list(title = "ï..age"))
f3
```

```{r}
f4 <- plot_ly(HeartDisease,
              type = "box") %>% 
  add_boxplot(y = ~thalach,
              x = ~target,
              name = "thalach") %>% 
  layout(title = "ï..age",
         xaxis = list(title = "target"),
         yaxis = list(title = "thalach"))
f4

```
```{r}
f5 <- plot_ly(HeartDisease,
              type = "box") %>% 
  add_boxplot(y = ~oldpeak,
              x = ~target,
              name = "oldpeak") %>% 
  layout(title = "oldpeak",
         xaxis = list(title = "target"),
         yaxis = list(title = "oldpeak"))
f5
```
```{r}
#Removing the non continuous varibles from the data set
heart.vars <- HeartDisease %>% dplyr::select(-one_of("target","cp","sex","fbs","ca"))
head(heart.vars)
```
```{r Shapiro-wilk test}
#testing for normality using shapiro-wilks test
mvnormtest::mshapiro.test(t(heart.vars))

#the hypothesis is that if the p-value is below .05 then we can assume normality in the distribution
```
```{r}
#determinant of variance-covariance matrix
det(cov(heart.vars))
```

```{r Hotelling test}
#Because it passed both the shapiro-wilks test and the determinant is positive, we can conclude that a hotelling t test can be used on the data. 
fit <- HotellingsT2(filter(heart,
                             target == "1") [c(1, 4, 5, 7, 8)],
                      filter(heart,
                             target == "0") [c(1, 4, 5, 7, 8)])
fit

#The hotellings T squared test shows that we have a p-value less than .05. This mean we can reject the null hypothesis that there is no multivariate difference between the two states of target. Accepting the alternative assumes there is a difference in sample means. 
```
```{r}
#Viewing and comparing discrete variables
table(heart$target, heart$sex)
table(heart$target, heart$fbs)
```


```{r}
#Viewing and comparing discrete variables
ggplot(heart) +
  aes(x=target, fill = fbs) +
  geom_bar() + 
  scale_fill_hue() + 
  theme_minimal()
```

```{r}
#using a chi-squared test to look for a difference in means between discrete variables. 
chi.test <- chisq.test(table(heart$target == 1, heart$sex))
chi.test

chi.test0 <- chisq.test(table(heart$target != 1, heart$sex))
chi.test0
```
```{r}
chi.test1 <- chisq.test(table(heart$target == 1, heart$fbs))
chi.test1

chi.test01 <- chisq.test(table(heart$target != 1, heart$fbs))
chi.test01

#For both FBS and SEX, I get a p-value of less than .05. This means I can reject the null hypothesis that there is no difference in means between the variables. 
```

```{r Split into training and testing}

#Using the split function to separate data into test and train
split = sample.split(heart$target, SplitRatio = 0.8)
train = subset(heart, split == TRUE)
test = subset(heart, split == FALSE)

head(train)
```


```{r PCA for Data}

#Doing a PCA to find out if I need to do any dimensional reduction
heart.pr <- prcomp(heart.vars, center = TRUE, scale = TRUE)
summary(heart.pr)
```
```{r Visualizing the PC values}
#Visualizing the variance in the PC Values
screeplot(heart.pr, type = "l", npcs = 5, main = "Screeplot of the 5 PCs")
abline(h = 1, col="red", lty=5)
legend("topright", legend=c("Eigenvalue = 1"),
       col=c("red"), lty=5, cex=0.6)

#The first 4 variables are enough to achieve 90 percent of the explained variance, but I decided to use all 5 variables since that is not too many dimensions to complicate the model. 
```

```{r}
#Using LDA to predict the outcome for target variable
#creation of lda model
heart.lda <- lda(target ~ ï..age + trestbps + chol + thalach + oldpeak, data = train)

#creating prediction
heart.lda.predict <- predict(heart.lda, newdata = test)
table(heart.lda.predict$class)

heart.lda.predict.posteriors <- as.data.frame(heart.lda.predict$posterior)
heart.lda.predict.posteriors

#visualization of the false positive and false negative rates
pred <- prediction(heart.lda.predict.posteriors[,2], test$target)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values

plot(roc.perf)
abline(a = 0, b = 1)
text(x = .2, y = .8 ,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
```

```{r}
#Another way to understand the misclassification rate
tab <- table(heart.lda.predict$class, test$target)
tab

1-sum(diag(tab))/sum(tab)
```
```{r}
#Using all PC values to create an LDA model, I was able to achieve a success rate of 74.1% I would say the reason the miscalssification rate is up above 30 is because an LDA model assumes linearity. If the true relationship of the variables is not linear then this will add to the uncertainty of the model.  
```

